---
title: "GLM in Jamovi"
output: 
  html_document:
     toc: true
     toc_float:
        collapsed: false
---

# General Linear Model example: Multiple regression, moderated regression, and simple slopes

In this example we tackle a moderated regression analysis with simple slopes analysis and simple slopes graphs. Data are from   [Cohen et al 2003](http://psycnet.apa.org/record/2002-18109-000) and can be downloaded  [here](https://github.com/mcfanda/gamlj/blob/master/data/exercise.csv)

# The research design

The research is about physical endurance associated with age and physical exercise. 245 participants were measured while jogging on a treadmill. Edurance was measured in minutes ('yendu' in the file). Participants' age (`xage` in years) and number of years of physical exercise (`zexer` in years) were recorded as well (in jamovi `Exploration` -> `Descriptive`)  

<img src="examples/glm1/desc.png" class="img-responsive" alt="">

The researcher is interested in studying the relationships between endurance, age, and exercising, with the hypothesis that the effect of age (expectedly negative) is moderated by exercise, such that the more participants work out (higher levels of `exer`) the less age negatively affects endurance. 

# Understanding the problem

We can think about this analytic problem as a multiple regression, where the effect of age and exercise can be estimated while keeping constant the other variable. However, the researcher puts forward a _moderation hypothesis_, because s/he expects the effect of age to change for different levels of exercising. We than need an interaction between age and exercise.

We first run a multiple regression (to warm up), then we estimate a multiple regression with an interaction (moderated regression) and we probe the interaction with a simple slope analysis and simple slope graphs. Technical details can be found in [Cohen et al 2003](http://psycnet.apa.org/record/2002-18109-000), or in [Preacher website](http://quantpsy.org/interact/interactions.htm).

# GLM

## Multiple regression

Jamovi GAMLj module for GLM requires to set the variables in the right field depending on their role in the model and their type. 

<img src="examples/glm1/variables.png" class="img-responsive" alt="">

Thus, we push `yendu` in the `Dependent Variable` field and both `xage` and `zexer` in the `Covariates` field, being both variables quantitative.

As soon as the variables are set, jamovi  fills in the tables in the output panel with the estimation results. However, it is worth noticing that the statistical model has been defined by default by the software: We can see that in the `Model` tab.

<img src="examples/glm1/model.png" class="img-responsive" alt="">

Jamovi, following a somehow old tradition established by SPSS, automatically includes continuous independent variables in the model without their interaction. For categorical variables the default behavior is to include both main effects and interactions.

Thus, the model we are estimating now is `yendu~xage+zexer`.

## Results

<img src="examples/glm1/resultsmr1.png" class="img-responsive" alt="">

Results show that both age and exercising have an effect on endurance while keeping constant the other variable. The ANOVA table shows also the R-squared, R-squared=.166, indicating the the two independent variables together explain around 16% of the dependent variable variance.

The `Model Coefficients` table reports the B coefficients estimates. We can interpret the B coefficients (under `Estimate` column  of `Model Coefficients` table) because the units of the variables are intuitively clear:

* `xage` B=-.257: While keeping exercise constant, one year more in age corresponds on average to a decrease in endurance of .257 minutes. 
* `zexer` B=-.916: While keeping age constant, one year more of exercising corresponds on average to an increase in endurance of .916 minutes.

For each coefficient the condidence interavals are also reported.

A special note should be made for the intercept (nobody interpret intercepts, but we do now). The intercept is the expected value (the mean) of the dependent variable, estimated for all independent variables equal to zero. In jamovi GLM, however, continuous variables are centered to their mean by default (this will prove very helpful later on), thus the interpretation of the intercept should be: the expected value of the dependent variable estimated for the average values of the independent variables. This is not bad, afterall, because 26.5 is actually the mean of the dependent variables (see descriptives above), thus a plot of the effects will be centered around the dependent variable means. In case we want the independent variables not to be centered, we can select a different scaling in the `Covariates Scaling' tab.

In general, we want to report standardized effect size indeces, for the sake of comparisons, meta-analyses, APA task forces (and probably the Marvel Avengers league). Jamovi GLM offers a plethora of them: 

* betas: standardized coefficients.
* eta-squared: proportion of variance explained over the total variance of the dependent variable.
* partial eta-squared: proportion of variance explained over the variance not explained by other effects.
* omega-squared: expected proportion of variance explained over the variance not explained by other effects, expected in the population.

By ticking the options in the variable definition panel, we obtain the ES indeces as follows.

<img src="examples/glm1/resultsmr2.png" class="img-responsive" alt="">


## Moderated regression

To include the interaction we simply add the interaction effect in the `Model Terms` under the `Model` tab.

<img src="examples/glm1/model2.png" class="img-responsive" alt="">

The interaction is pushed in the `Model Terms` by selecting the variables on the left and click `interaction` in the "arrow" cascade menu.

<img src="glm/interactions.png" class="img-responsive" alt="">

## Results

Let's us first focus on the parameters estimates, the B coefficients.

<img src="examples/glm1/resultsmoderate.png" class="img-responsive" alt="">

The interaction term appears to be statistically significant, B=0.047, t(241)=3.48,p<.001,eta^2=0.048, justifying interpreting the first-order effects as conditional effects. Because we have centered the variables to their means, we can interpret the first-order effect as "average" effects. On average:

* `xage` B=-.261:  one year more in age corresponds on average to a decrease in endurance of .26 minutes. 
* `zexer` B=-.972:  one year more of exercising corresponds on average to an increase in endurance of .97 minutes.

One can also report the betas (last column in the `Model Coefficients` table). Please notice that Jamovi GLM the estimates of the betas are correct also in the presence of the interaction, because the variables are standardized before the interaction term is computed.

## Simple Slopes

We can now probe the interaction. We go to `Simple effects` tab and select `xage`  as `Simple effec variable` and `zexer` as `Moderator`. In this way we obtain the effect of age computed for high exercise (`zexer` centered to 1 SD above average), the main effect of age (`zexer` centered to 1 SD above average) and the effect of age computed for low exercise (`zexer` centered to -1 SD above average).

Jamovi GLM produces both the F-tests and the parameter estimates for the simple slopes. We focus on the latter table now.

<img src="examples/glm1/resultssimple.png" class="img-responsive" alt="">

The first row of the table shows the simple slope of age (the effect of age) computed for exercise equal to minus one standard deviation (-4.78). The effect of age is negative and strong ,B=-.487, t(241)=-5.289,p<.001. Going down the table we find  the simple slope of age (the effect of age) computed for average exercise (0). The effect of age is negative and but weaker than for high exercise ,B=-.261, t(241)=-4.085,p<.001. Finally, for high exercise (+4.78), the effect is weak and not significant, B=-.036, t(241)=-0.400,p=.690.

## Simple Slopes Plot

We can get a clear picture of the interaction by asking for a plot. Also the plot module takes care of centering the variables in a way that makes the plot clearly understandable. 

<img src="examples/glm1/plots.png" class="img-responsive" alt="">

It plots the effect of the `Horizontal axis` variable for three levels (-1 SD, mean, +1 SD) of the `Separate Lines` variable. 

<img src="examples/glm1/resultsplot.png" class="img-responsive" alt="">

The nice plot we get shows the simple effects (simple equations to be precise) with the prediction confidence intervals indicated by the colored shades around the lines. If needed, the confidence intervals can be substituted with the standard errors of the estimates or they can be removed completely.
